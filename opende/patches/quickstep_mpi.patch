Index: ode/src/quickstep.cpp
===================================================================
--- ode/src/quickstep.cpp	(revision 1755)
+++ ode/src/quickstep.cpp	(working copy)
@@ -33,6 +33,29 @@
 #include "lcp.h"
 #include "util.h"
 
+#include <sys/time.h>
+
+
+//#include <mpi.h>
+
+#undef REPORT_THREAD_TIMING
+#define USE_TPROW
+#undef TIMING
+#undef REPORT_MONITOR
+#undef SHOW_CONVERGENCE
+#define LOCAL_STEPPING
+#undef RECOMPUTE_RMS
+#undef USE_1NORM
+
+
+
+#ifdef USE_TPROW
+// added for threading per constraint rows
+#include <boost/thread/recursive_mutex.hpp>
+#include <boost/bind.hpp>
+#include "ode/odeinit.h"
+#endif
+
 typedef const dReal *dRealPtr;
 typedef dReal *dRealMutablePtr;
 
@@ -62,6 +85,7 @@
 // or hardly at all, but it doesn't seem to hurt.
 
 #define RANDOMLY_REORDER_CONSTRAINTS 1
+#undef LOCK_WHILE_RANDOMLY_REORDER_CONSTRAINTS
 
 #define USE_JOINT_DAMPING
 
@@ -341,15 +365,469 @@
 
 #endif
 
+
+static void ComputeRows(
+                int thread_id,
+                IndexError* order,
+                dxBody* const *body,
+                int* tmpInt,
+                dReal* tmpReal,
+                const int** tmpIntPtr,
+                dRealPtr* tmpRealPtr,
+                dRealMutablePtr* tmpMutablePtr,
+                boost::recursive_mutex* mutex)
+{
+  struct timeval tv;
+  double cur_time;
+  gettimeofday(&tv,NULL);
+  cur_time = (double)tv.tv_sec + (double)tv.tv_usec / 1.e6;
+  //printf("thread %d started at time %f\n",thread_id,cur_time);
+
+  //boost::recursive_mutex::scoped_lock lock(*mutex); // put in fc read/writes?
+  int startRow           = tmpInt[0];
+  int nRows              = tmpInt[1];
+  int m                  = tmpInt[2];
+  int nb                 = tmpInt[3];
+  int m_damp             = tmpInt[4];
+  int num_iterations     = tmpInt[5];
+  dReal stepsize         = tmpReal[0];
+  dReal sor_lcp_tol      = tmpReal[1];
+  const int* jb                = tmpIntPtr[0];
+  const int* findex            = tmpIntPtr[1];
+  const int* jb_damp           = tmpIntPtr[2];
+  dRealPtr        Ad           = tmpRealPtr[0];
+  dRealPtr        hi           = tmpRealPtr[1];
+  dRealPtr        lo           = tmpRealPtr[2];
+  dRealPtr        Adcfm        = tmpRealPtr[3];
+  dRealPtr        JiM          = tmpRealPtr[4];
+  dRealPtr        invI         = tmpRealPtr[5];
+  dRealPtr        coeff_damp   = tmpRealPtr[6];
+  dRealMutablePtr b            = tmpMutablePtr[0];
+  dRealMutablePtr J            = tmpMutablePtr[1];
+  dRealMutablePtr fc           = tmpMutablePtr[2];
+  dRealMutablePtr lambda       = tmpMutablePtr[3];
+  dRealMutablePtr iMJ          = tmpMutablePtr[4];
+#ifdef USE_JOINT_DAMPING
+  dRealMutablePtr b_damp       = tmpMutablePtr[5];
+  dRealMutablePtr f_damp       = tmpMutablePtr[6];
+  dRealMutablePtr v_damp       = tmpMutablePtr[7];
+  dRealMutablePtr J_damp       = tmpMutablePtr[8];
+  dRealMutablePtr v_joint_damp = tmpMutablePtr[9];
+#ifdef REORDER_CONSTRAINTS
+  dRealMutablePtr last_lambda  = tmpMutablePtr[10];
+#endif
+#endif
+  dRealMutablePtr delta_error  = tmpMutablePtr[11];
+  dRealMutablePtr lambda_qr    = tmpMutablePtr[12];
+
+  //printf("iiiiiiiii %d %d %d\n",thread_id,jb[0],jb[1]);
+  //for (int i=startRow; i<startRow+nRows; i++) // swap within boundary of our own segment
+  //  printf("wwwwwwwwwwwww>id %d start %d n %d  order[%d].index=%d\n",thread_id,startRow,nRows,i,order[i].index);
+
+  for (int iteration=0; iteration < num_iterations; iteration++) {
+
+#ifdef REORDER_CONSTRAINTS
+    // FIXME: lambda_qr not swapped here
+    // constraints with findex < 0 always come first.
+    if (iteration < 2) {
+      // for the first two iterations, solve the constraints in
+      // the given order
+      IndexError *ordercurr = order+startRow;
+      //for (int i = 0; i != m; ordercurr++, i++) { }
+      for (int i = startRow; i != startRow+nRows; ordercurr++, i++) {
+        ordercurr->error = i;
+        ordercurr->findex = findex[i];
+        ordercurr->index = i;
+      }
+    }
+    else {
+      // sort the constraints so that the ones converging slowest
+      // get solved last. use the absolute (not relative) error.
+      //for (int i=0; i<m; i++) { }
+      for (int i=startRow; i<startRow+nRows; i++) {
+        dReal v1 = dFabs (lambda[i]);
+        dReal v2 = dFabs (last_lambda[i]);
+        dReal max = (v1 > v2) ? v1 : v2;
+        if (max > 0) {
+          //@@@ relative error: order[i].error = dFabs(lambda[i]-last_lambda[i])/max;
+          order[i].error = dFabs(lambda[i]-last_lambda[i]);
+        }
+        else {
+          order[i].error = dInfinity;
+        }
+        order[i].findex = findex[i];
+        order[i].index = i;
+      }
+    }
+
+    //if (thread_id == 0) for (int i=startRow;i<startRow+nRows;i++) printf("=====> %d %d %d %f %d\n",thread_id,iteration,i,order[i].error,order[i].index);
+
+    //qsort (order,m,sizeof(IndexError),&compare_index_error);
+    qsort (order+startRow,nRows,sizeof(IndexError),&compare_index_error);
+
+    //@@@ potential optimization: swap lambda and last_lambda pointers rather
+    //    than copying the data. we must make sure lambda is properly
+    //    returned to the caller
+    //memcpy (last_lambda,lambda,m*sizeof(dReal));
+    memcpy (last_lambda+startRow,lambda+startRow,nRows*sizeof(dReal));
+
+    //if (thread_id == 0) for (int i=startRow;i<startRow+nRows;i++) printf("-----> %d %d %d %f %d\n",thread_id,iteration,i,order[i].error,order[i].index);
+
+#endif
+#ifdef RANDOMLY_REORDER_CONSTRAINTS
+    if ((iteration & 7) == 0) {
+      #ifdef LOCK_WHILE_RANDOMLY_REORDER_CONSTRAINTS
+        boost::recursive_mutex::scoped_lock lock(*mutex); // lock for every swap
+      #endif
+      //for (int i=1; i<m; i++) {}   // swap across engire matrix
+      //  int swapi = dRandInt(i+1); // swap across engire matrix
+      for (int i=startRow+1; i<startRow+nRows; i++) { // swap within boundary of our own segment
+        int swapi = dRandInt(i+1-startRow)+startRow; // swap within boundary of our own segment
+        //printf("xxxxxxxx>id %d swaping order[%d].index=%d order[%d].index=%d\n",thread_id,i,order[i].index,swapi,order[swapi].index);
+        IndexError tmp = order[i];
+        order[i] = order[swapi];
+        order[swapi] = tmp;
+      }
+
+      // {
+      //   // verify
+      //   boost::recursive_mutex::scoped_lock lock(*mutex); // lock for every row
+      //   printf("  random id %d iter %d\n",thread_id,iteration);
+      //   for (int i=startRow+1; i<startRow+nRows; i++)
+      //     printf(" %5d,",i);
+      //   printf("\n");
+      //   for (int i=startRow+1; i<startRow+nRows; i++)
+      //     printf(" %5d;",(int)order[i].index);
+      //   printf("\n");
+      // }
+    }
+#endif
+
+    //dSetZero (delta_error,m);
+    dReal rms_error = 0;
+
+    for (int i=startRow; i<startRow+nRows; i++) {
+
+      //boost::recursive_mutex::scoped_lock lock(*mutex); // lock for every row
+
+      // @@@ potential optimization: we could pre-sort J and iMJ, thereby
+      //     linearizing access to those arrays. hmmm, this does not seem
+      //     like a win, but we should think carefully about our memory
+      //     access pattern.
+
+      int index = order[i].index;
+
+      dReal qr = (dReal)(i+1 + 0*iteration*nRows);
+
+      if (lambda_qr[index] < qr)
+      {
+
+        // update and set qr
+        lambda_qr[index] = qr;
+
+        dRealMutablePtr fc_ptr1;
+        dRealMutablePtr fc_ptr2;
+        dReal delta;
+
+        {
+          int b1 = jb[index*2];
+          int b2 = jb[index*2+1];
+          fc_ptr1 = fc + 6*b1;
+          fc_ptr2 = (b2 >= 0) ? fc + 6*b2 : NULL;
+        }
+
+#ifdef USE_JOINT_DAMPING
+        /*************************************************************/
+        /* compute b_damp                                            */
+        /* b is to be modified by b_damp                             */
+        /* where b_damp = -J*inv(M)*f_damp / Ad  (since b is rhs/Ad) */
+        /*                                                           */
+        /* initially f_damp is 0, so motion is undamped on first     */
+        /* iteration.                                                */
+        /*                                                           */
+        /*************************************************************/
+        {
+          b_damp[index] = 0;
+          int b1 = jb[index*2];
+          int b2 = jb[index*2+1];
+          dRealMutablePtr f_damp_ptr1 = f_damp + 6*b1;
+          dRealMutablePtr f_damp_ptr2 = (b2 >= 0) ? f_damp + 6*b2 : NULL;
+     
+          dRealPtr JiM_ptr = JiM + index*12;
+
+          // compute b_damp = JiM * f_damp, b_damp is preset to zero already
+          for (int j=0;j<6;j++) {
+            b_damp[index] += JiM_ptr[j] * f_damp_ptr1[j];
+            if (b2>=0) b_damp[index] += JiM_ptr[j+6] * f_damp_ptr2[j];
+          }
+     
+          // and scale JiM by Ad
+          b_damp[index] *= Ad[index];
+          // FIXME: find some kind of limiters that works as artificial dampers
+          // b_damp must make b smaller
+          // so b_damp must have opposite sign as b
+          // and abs(b_damp) < abs(b)
+          //if (b_damp[index]*b[index]>0) b_damp[index]=0;
+          //if (dFabs(b_damp[index])>dFabs(b[index])) b_damp[index]=-b[index];
+        }
+#endif
+
+        dReal old_lambda = lambda[index];
+
+        {
+          delta = b[index] - old_lambda*Adcfm[index];
+#ifdef USE_JOINT_DAMPING
+          /***************************************************************************/
+          /* b is to be modified by b_damp = -J*inv(M)*f_damp / Ad since b is rhs/Ad */
+          /***************************************************************************/
+          delta += b_damp[index];
+#endif
+
+          dRealPtr J_ptr = J + index*12;
+          // @@@ potential optimization: SIMD-ize this and the b2 >= 0 case
+          delta -=fc_ptr1[0] * J_ptr[0] + fc_ptr1[1] * J_ptr[1] +
+            fc_ptr1[2] * J_ptr[2] + fc_ptr1[3] * J_ptr[3] +
+            fc_ptr1[4] * J_ptr[4] + fc_ptr1[5] * J_ptr[5];
+          // @@@ potential optimization: handle 1-body constraints in a separate
+          //     loop to avoid the cost of test & jump?
+          if (fc_ptr2) {
+            delta -=fc_ptr2[0] * J_ptr[6] + fc_ptr2[1] * J_ptr[7] +
+              fc_ptr2[2] * J_ptr[8] + fc_ptr2[3] * J_ptr[9] +
+              fc_ptr2[4] * J_ptr[10] + fc_ptr2[5] * J_ptr[11];
+          }
+        }
+
+        {
+          dReal hi_act, lo_act;
+
+          // set the limits for this constraint. 
+          // this is the place where the QuickStep method differs from the
+          // direct LCP solving method, since that method only performs this
+          // limit adjustment once per time step, whereas this method performs
+          // once per iteration per constraint row.
+          // the constraints are ordered so that all lambda[] values needed have
+          // already been computed.
+          if (findex[index] >= 0) {
+            hi_act = dFabs (hi[index] * lambda[findex[index]]);
+            lo_act = -hi_act;
+          } else {
+            hi_act = hi[index];
+            lo_act = lo[index];
+          }
+
+          // compute lambda and clamp it to [lo,hi].
+          // @@@ potential optimization: does SSE have clamping instructions
+          //     to save test+jump penalties here?
+          dReal new_lambda = old_lambda + delta;
+          if (new_lambda < lo_act) {
+            delta = lo_act-old_lambda;
+            lambda[index] = lo_act;
+          }
+          else if (new_lambda > hi_act) {
+            delta = hi_act-old_lambda;
+            lambda[index] = hi_act;
+          }
+          else {
+            lambda[index] = new_lambda;
+          }
+        }
+
+        rms_error += delta*delta;
+        delta_error[index] = dFabs(delta);
+
+        //@@@ a trick that may or may not help
+        //dReal ramp = (1-((dReal)(iteration+1)/(dReal)num_iterations));
+        //delta *= ramp;
+        
+        {
+          dRealPtr iMJ_ptr = iMJ + index*12;
+          // update fc.
+          // @@@ potential optimization: SIMD for this and the b2 >= 0 case
+          fc_ptr1[0] += delta * iMJ_ptr[0];
+          fc_ptr1[1] += delta * iMJ_ptr[1];
+          fc_ptr1[2] += delta * iMJ_ptr[2];
+          fc_ptr1[3] += delta * iMJ_ptr[3];
+          fc_ptr1[4] += delta * iMJ_ptr[4];
+          fc_ptr1[5] += delta * iMJ_ptr[5];
+          // @@@ potential optimization: handle 1-body constraints in a separate
+          //     loop to avoid the cost of test & jump?
+          if (fc_ptr2) {
+            fc_ptr2[0] += delta * iMJ_ptr[6];
+            fc_ptr2[1] += delta * iMJ_ptr[7];
+            fc_ptr2[2] += delta * iMJ_ptr[8];
+            fc_ptr2[3] += delta * iMJ_ptr[9];
+            fc_ptr2[4] += delta * iMJ_ptr[10];
+            fc_ptr2[5] += delta * iMJ_ptr[11];
+          }
+        }
+      } // lambda_qr
+    } // end of for loop on m
+
+
+// do we need to compute norm across entire solution space (0,m)?
+// since local convergence might produce errors in other nodes?
+#ifdef RECOMPUTE_RMS
+    // recompute rms_error to be sure swap is not corrupting arrays
+    rms_error = 0;
+#ifdef USE_1NORM
+    //for (int i=startRow; i<startRow+nRows; i++)
+    for (int i=0; i<m; i++)
+    {
+      rms_error = dFabs(delta_error[order[i].index]) > rms_error ? dFabs(delta_error[order[i].index]) : rms_error; // 1norm test
+    }
+#else // use 2 norm
+    //for (int i=startRow; i<startRow+nRows; i++)
+    for (int i=0; i<m; i++)  // use entire solution vector errors
+      rms_error += delta_error[order[i].index]*delta_error[order[i].index]; ///(dReal)nRows;
+    rms_error = sqrt(rms_error); ///(dReal)nRows;
+#endif
+#else
+    rms_error = sqrt(rms_error); ///(dReal)nRows;
+#endif
+
+    //printf("------ %d %d %20.18f\n",thread_id,iteration,rms_error);
+
+    //for (int i=startRow; i<startRow+nRows; i++) printf("debug: %d %f\n",i,delta_error[i]);
+
+
+    //{
+    //  // verify
+    //  boost::recursive_mutex::scoped_lock lock(*mutex); // lock for every row
+    //  printf("  random id %d iter %d\n",thread_id,iteration);
+    //  for (int i=startRow+1; i<startRow+nRows; i++)
+    //    printf(" %10d,",i);
+    //  printf("\n");
+    //  for (int i=startRow+1; i<startRow+nRows; i++)
+    //    printf(" %10d;",order[i].index);
+    //  printf("\n");
+    //  for (int i=startRow+1; i<startRow+nRows; i++)
+    //    printf(" %10.8f,",delta_error[i]);
+    //  printf("\n%f\n",rms_error);
+    //}
+
+
+#ifdef USE_JOINT_DAMPING
+    /****************************************************************/
+    /* compute v_damp per fc update                                 */
+    /*   based on all external forces fe, fc, f_damp                */
+    /*   v_damp should have started out same as v(n)                */
+    /*   v_damp should end up being v(n+1)                          */
+    /*                                                              */
+    /*  v_damp = v_current + stepsize * invM * f_all                */
+    /*                                                              */
+    /****************************************************************/
+    {
+      const dReal *invIrow = invI;
+      dRealMutablePtr f_damp_ptr = f_damp;
+      dRealMutablePtr v_damp_ptr = v_damp;
+      dxBody *const *const bodyend = body + nb;
+      const dReal *fc_ptr = fc;
+
+      for (dxBody *const *bodycurr = body; bodycurr != bodyend; fc_ptr+=6, invIrow += 12, f_damp_ptr+=6, v_damp_ptr+=6, bodycurr++) {
+        // f_damp should be updated in SOR LCP
+
+        // compute the velocity update:
+        // add stepsize * invM * f_damp to the body velocity
+        dxBody *b = *bodycurr;
+        dReal body_invMass_mul_stepsize = stepsize * b->invMass;
+        dReal tmp3[3];
+        for (int j=0; j<3; j++) {
+          // note that cforce(fc) is really not a force but an acceleration, hence there is
+          // no premultiplying of invM here (compare to update due to external force 'facc' below)
+          // add stepsize * cforce(fc) to the body velocity
+          v_damp_ptr[j]   = b->lvel[j] + stepsize * fc_ptr[j]   + body_invMass_mul_stepsize * ( b->facc[j] + f_damp_ptr[j] );
+          v_damp_ptr[j+3] = b->avel[j] + stepsize * fc_ptr[j+3];
+
+          // accumulate step*torques
+          tmp3[j] = stepsize*(b->tacc[j] + f_damp_ptr[j+3]);
+        }
+        // v_damp = invI * f_damp
+        dMultiplyAdd0_331 (v_damp_ptr+3, invIrow, tmp3);
+
+      }
+    }
+
+    /****************************************************************/
+    /* compute f_damp per v_damp update                             */
+    /* compute damping force f_damp = J_damp' * B * J_damp * v_damp */
+    /*                                                              */
+    /*  we probably want to apply some kind of limiter on f_damp    */
+    /*  based on changes in v_damp.                                 */
+    /*                                                              */
+    /*  for starters, ramp up damping to increase stability.        */
+    /*                                                              */
+    /****************************************************************/
+    {
+      dSetZero (f_damp,6*nb); // reset f_damp, following update skips around, so cannot set to 0 inline
+      dRealPtr J_damp_ptr = J_damp;
+      // compute f_damp and velocity updates
+      // first compute v_joint_damp = J_damp * v_damp
+      // v_joint_damp is m_damp X 1 single column vector
+      for (int j=0; j<m_damp;J_damp_ptr+=12, j++) {
+        int b1 = jb_damp[j*2];
+        int b2 = jb_damp[j*2+1];
+        v_joint_damp[j] = 0;
+
+        // ramp-up : option to skip first few iterations to let the joint settle first
+        int skip = 10; //num_iterations-1;
+        dReal alpha = (iteration>=skip)?(dReal)(iteration-skip+1) / (dReal)(num_iterations-skip):0;
+
+        for (int k=0;k<6;k++) v_joint_damp[j] += alpha*J_damp_ptr[k] * v_damp[b1*6+k];
+        if (b2 >= 0) for (int k=0;k<6;k++) v_joint_damp[j] += alpha*J_damp_ptr[k+6] * v_damp[b2*6+k];
+        // multiply by damping coefficients (B is diagnoal)
+        v_joint_damp[j] *= coeff_damp[j];
+
+        // so now v_joint_damp = B * J_damp * v_damp
+        // update f_damp = J_damp' * v_joint_damp
+        for (int k=0; k<6; k++) f_damp[b1*6+k] -= J_damp_ptr[k]*v_joint_damp[j];
+        if (b2 >= 0) for (int k=0; k<6; k++) f_damp[b2*6+k] -= J_damp_ptr[6+k]*v_joint_damp[j];
+
+        //if (v_joint_damp[j] < 1000)
+        //  printf("ITER: %d j: %d m1: %f m2: %f v: %f\n",iteration,j,1.0/body[b1]->invMass,1.0/body[b2]->invMass,v_joint_damp[j]);
+      }
+
+    }
+#endif
+
+#ifdef SHOW_CONVERGENCE
+    printf("MONITOR: id: %d iteration: %d error: %20.16f\n",thread_id,iteration,rms_error);
+#endif
+
+    if (rms_error < sor_lcp_tol)
+    {
+      #ifdef REPORT_MONITOR
+        printf("CONVERGED: id: %d steps: %d rms(%20.18f)\n",thread_id,iteration,rms_error);
+      #endif
+      break;
+    }
+    else if (iteration == num_iterations -1)
+    {
+      #ifdef REPORT_MONITOR
+        printf("**********ERROR: id: %d did not converge in %d steps, rms(%20.18f)\n",thread_id,num_iterations,rms_error);
+      #endif
+    }
+
+  } // end of for loop on iterations
+
+  gettimeofday(&tv,NULL);
+  double end_time = (double)tv.tv_sec + (double)tv.tv_usec / 1.e6;
+  #ifdef REPORT_THREAD_TIMING
+  printf("      quickstep row thread %d start time %f ended time %f duration %f\n",thread_id,cur_time,end_time,end_time - cur_time);
+  #endif
+}
+
 static void SOR_LCP (dxWorldProcessContext *context,
   const int m, const int nb, dRealMutablePtr J, int *jb, dxBody * const *body,
-  dRealPtr invI, dRealMutablePtr lambda, dRealMutablePtr fc, dRealMutablePtr b,
+  dRealPtr invI, dRealMutablePtr lambda, dRealMutablePtr lambda_qr, dRealMutablePtr fc, dRealMutablePtr b,
   dRealPtr lo, dRealPtr hi, dRealPtr cfm, const int *findex,
   const dxQuickStepParameters *qs,
 #ifdef USE_JOINT_DAMPING
   const int m_damp,dRealMutablePtr J_damp, dRealPtr coeff_damp, int *jb_damp,dRealMutablePtr v_damp,
   dRealMutablePtr f_damp,dRealMutablePtr v_joint_damp, dRealPtr JiM, // damping related
 #endif
+#ifdef USE_TPROW
+  boost::threadpool::pool* row_threadpool,
+#endif
   const dReal stepsize) // for updating v_damp along the way
 {
 #ifdef WARM_STARTING
@@ -360,6 +838,7 @@
   }
 #else
   dSetZero (lambda,m);
+  dSetZero (lambda_qr,m);
 #endif
 
   // precompute iMJ = inv(M)*J'
@@ -420,6 +899,8 @@
   // order to solve constraint rows in
   IndexError *order = context->AllocateArray<IndexError> (m);
 
+  dReal *delta_error = context->AllocateArray<dReal> (m);
+
 #ifndef REORDER_CONSTRAINTS
   {
     // make sure constraints with findex < 0 come first.
@@ -449,241 +930,114 @@
   dReal *b_damp = context->AllocateArray<dReal> (m);
 #endif
 
+
+  boost::recursive_mutex* mutex = new boost::recursive_mutex();
+
   const int num_iterations = qs->num_iterations;
-  for (int iteration=0; iteration < num_iterations; iteration++) {
+  // single iteration, through all the constraints
 
-#ifdef REORDER_CONSTRAINTS
-    // constraints with findex < 0 always come first.
-    if (iteration < 2) {
-      // for the first two iterations, solve the constraints in
-      // the given order
-      IndexError *ordercurr = order;
-      for (int i = 0; i != m; ordercurr++, i++) {
-        ordercurr->error = i;
-        ordercurr->findex = findex[i];
-        ordercurr->index = i;
-      }
-    }
-    else {
-      // sort the constraints so that the ones converging slowest
-      // get solved last. use the absolute (not relative) error.
-      for (int i=0; i<m; i++) {
-        dReal v1 = dFabs (lambda[i]);
-        dReal v2 = dFabs (last_lambda[i]);
-        dReal max = (v1 > v2) ? v1 : v2;
-        if (max > 0) {
-          //@@@ relative error: order[i].error = dFabs(lambda[i]-last_lambda[i])/max;
-          order[i].error = dFabs(lambda[i]-last_lambda[i]);
-        }
-        else {
-          order[i].error = dInfinity;
-        }
-        order[i].findex = findex[i];
-        order[i].index = i;
-      }
-    }
-    qsort (order,m,sizeof(IndexError),&compare_index_error);
 
-    //@@@ potential optimization: swap lambda and last_lambda pointers rather
-    //    than copying the data. we must make sure lambda is properly
-    //    returned to the caller
-    memcpy (last_lambda,lambda,m*sizeof(dReal));
-#endif
-#ifdef RANDOMLY_REORDER_CONSTRAINTS
-    if ((iteration & 7) == 0) {
-      for (int i=1; i<m; i++) {
-        int swapi = dRandInt(i+1);
-        IndexError tmp = order[i];
-        order[i] = order[swapi];
-        order[swapi] = tmp;
-      }
-    }
-#endif
 
-    for (int i=0; i<m; i++) {
-      // @@@ potential optimization: we could pre-sort J and iMJ, thereby
-      //     linearizing access to those arrays. hmmm, this does not seem
-      //     like a win, but we should think carefully about our memory
-      //     access pattern.
 
-      int index = order[i].index;
 
-      dRealMutablePtr fc_ptr1;
-      dRealMutablePtr fc_ptr2;
-      dReal delta;
 
-      {
-        int b1 = jb[index*2];
-        int b2 = jb[index*2+1];
-        fc_ptr1 = fc + 6*b1;
-        fc_ptr2 = (b2 >= 0) ? fc + 6*b2 : NULL;
-      }
 
-#ifdef USE_JOINT_DAMPING
-      /*************************************************************/
-      /* compute b_damp                                            */
-      /* b is to be modified by b_damp                             */
-      /* where b_damp = -J*inv(M)*f_damp / Ad  (since b is rhs/Ad) */
-      /*                                                           */
-      /* initially f_damp is 0, so motion is undamped on first     */
-      /* iteration.                                                */
-      /*                                                           */
-      /*************************************************************/
-      {
-        b_damp[index] = 0;
-        int b1 = jb[index*2];
-        int b2 = jb[index*2+1];
-        dRealMutablePtr f_damp_ptr1 = f_damp + 6*b1;
-        dRealMutablePtr f_damp_ptr2 = (b2 >= 0) ? f_damp + 6*b2 : NULL;
-   
-        dRealPtr JiM_ptr = JiM + index*12;
 
-        // compute b_damp = JiM * f_damp, b_damp is preset to zero already
-        for (int j=0;j<6;j++) {
-          b_damp[index] += JiM_ptr[j] * f_damp_ptr1[j];
-          if (b2>=0) b_damp[index] += JiM_ptr[j+6] * f_damp_ptr2[j];
-        }
-   
-        // and scale JiM by Ad
-        b_damp[index] *= Ad[index];
-        // FIXME: find some kind of limiters that works as artificial dampers
-        // b_damp must make b smaller
-        // so b_damp must have opposite sign as b
-        // and abs(b_damp) < abs(b)
-        //if (b_damp[index]*b[index]>0) b_damp[index]=0;
-        //if (dFabs(b_damp[index])>dFabs(b[index])) b_damp[index]=-b[index];
-      }
-#endif
 
-      dReal old_lambda = lambda[index];
+  int num_chunks = qs->num_chunks;
 
-      {
-        delta = b[index] - old_lambda*Adcfm[index];
-#ifdef USE_JOINT_DAMPING
-        /***************************************************************************/
-        /* b is to be modified by b_damp = -J*inv(M)*f_damp / Ad since b is rhs/Ad */
-        /***************************************************************************/
-        delta += b_damp[index];
-#endif
+  // prepare pointers for threads
+  int tmpInt_size = 6;
+  int tmpInt[tmpInt_size*num_chunks];
+  int tmpReal_size = 2;
+  dReal tmpReal[tmpReal_size*num_chunks];
+  int tmpIntPtr_size = 3;
+  const int* tmpIntPtr[tmpIntPtr_size*num_chunks];
+  int tmpRealPtr_size = 7;
+  dRealPtr tmpRealPtr[tmpRealPtr_size*num_chunks];
+  int tmpMutablePtr_size = 13;
+  dRealMutablePtr tmpMutablePtr[tmpMutablePtr_size*num_chunks];
 
-        dRealPtr J_ptr = J + index*12;
-        // @@@ potential optimization: SIMD-ize this and the b2 >= 0 case
-        delta -=fc_ptr1[0] * J_ptr[0] + fc_ptr1[1] * J_ptr[1] +
-          fc_ptr1[2] * J_ptr[2] + fc_ptr1[3] * J_ptr[3] +
-          fc_ptr1[4] * J_ptr[4] + fc_ptr1[5] * J_ptr[5];
-        // @@@ potential optimization: handle 1-body constraints in a separate
-        //     loop to avoid the cost of test & jump?
-        if (fc_ptr2) {
-          delta -=fc_ptr2[0] * J_ptr[6] + fc_ptr2[1] * J_ptr[7] +
-            fc_ptr2[2] * J_ptr[8] + fc_ptr2[3] * J_ptr[9] +
-            fc_ptr2[4] * J_ptr[10] + fc_ptr2[5] * J_ptr[11];
-        }
-      }
+  int num_overlap = qs->num_overlap;
+  int chunk = m / num_chunks+1;
+  chunk = chunk > 0 ? chunk : 1;
+  int thread_id = 0;
 
-      {
-        dReal hi_act, lo_act;
 
-        // set the limits for this constraint. 
-        // this is the place where the QuickStep method differs from the
-        // direct LCP solving method, since that method only performs this
-        // limit adjustment once per time step, whereas this method performs
-        // once per iteration per constraint row.
-        // the constraints are ordered so that all lambda[] values needed have
-        // already been computed.
-        if (findex[index] >= 0) {
-          hi_act = dFabs (hi[index] * lambda[findex[index]]);
-          lo_act = -hi_act;
-        } else {
-          hi_act = hi[index];
-          lo_act = lo[index];
-        }
 
-        // compute lambda and clamp it to [lo,hi].
-        // @@@ potential optimization: does SSE have clamping instructions
-        //     to save test+jump penalties here?
-        dReal new_lambda = old_lambda + delta;
-        if (new_lambda < lo_act) {
-          delta = lo_act-old_lambda;
-          lambda[index] = lo_act;
-        }
-        else if (new_lambda > hi_act) {
-          delta = hi_act-old_lambda;
-          lambda[index] = hi_act;
-        }
-        else {
-          lambda[index] = new_lambda;
-        }
-      }
 
-      //@@@ a trick that may or may not help
-      //dReal ramp = (1-((dReal)(iteration+1)/(dReal)num_iterations));
-      //delta *= ramp;
-      
-      {
-        dRealPtr iMJ_ptr = iMJ + index*12;
-        // update fc.
-        // @@@ potential optimization: SIMD for this and the b2 >= 0 case
-        fc_ptr1[0] += delta * iMJ_ptr[0];
-        fc_ptr1[1] += delta * iMJ_ptr[1];
-        fc_ptr1[2] += delta * iMJ_ptr[2];
-        fc_ptr1[3] += delta * iMJ_ptr[3];
-        fc_ptr1[4] += delta * iMJ_ptr[4];
-        fc_ptr1[5] += delta * iMJ_ptr[5];
-        // @@@ potential optimization: handle 1-body constraints in a separate
-        //     loop to avoid the cost of test & jump?
-        if (fc_ptr2) {
-          fc_ptr2[0] += delta * iMJ_ptr[6];
-          fc_ptr2[1] += delta * iMJ_ptr[7];
-          fc_ptr2[2] += delta * iMJ_ptr[8];
-          fc_ptr2[3] += delta * iMJ_ptr[9];
-          fc_ptr2[4] += delta * iMJ_ptr[10];
-          fc_ptr2[5] += delta * iMJ_ptr[11];
-        }
-      }
+  struct timeval tv;
+  double cur_time;
+  gettimeofday(&tv,NULL);
+  cur_time = (double)tv.tv_sec + (double)tv.tv_usec / 1.e6;
+  //printf("    quickstep start threads at time %f\n",cur_time);
 
-    } // end of for loop on m
 
-#ifdef USE_JOINT_DAMPING
-    /****************************************************************/
-    /* compute v_damp per fc update                                 */
-    /*   based on all external forces fe, fc, f_damp                */
-    /*   v_damp should have started out same as v(n)                */
-    /*   v_damp should end up being v(n+1)                          */
-    /*                                                              */
-    /*  v_damp = v_current + stepsize * invM * f_all                */
-    /*                                                              */
-    /****************************************************************/
-    {
-      IFTIMING (dTimerNow ("velocity update due to f_damp"));
-      const dReal *invIrow = invI;
-      dRealMutablePtr f_damp_ptr = f_damp;
-      dRealMutablePtr v_damp_ptr = v_damp;
-      dxBody *const *const bodyend = body + nb;
-      const dReal *fc_ptr = fc;
 
-      for (dxBody *const *bodycurr = body; bodycurr != bodyend; fc_ptr+=6, invIrow += 12, f_damp_ptr+=6, v_damp_ptr+=6, bodycurr++) {
-        // f_damp should be updated in SOR LCP
 
-        // compute the velocity update:
-        // add stepsize * invM * f_damp to the body velocity
-        dxBody *b = *bodycurr;
-        dReal body_invMass_mul_stepsize = stepsize * b->invMass;
-        dReal tmp3[3];
-        for (int j=0; j<3; j++) {
-          // note that cforce(fc) is really not a force but an acceleration, hence there is
-          // no premultiplying of invM here (compare to update due to external force 'facc' below)
-          // add stepsize * cforce(fc) to the body velocity
-          v_damp_ptr[j]   = b->lvel[j] + stepsize * fc_ptr[j]   + body_invMass_mul_stepsize * ( b->facc[j] + f_damp_ptr[j] );
-          v_damp_ptr[j+3] = b->avel[j] + stepsize * fc_ptr[j+3];
+  IFTIMING (dTimerNow ("start pgs rows"));
+  for (int i=0; i<m; i+= chunk,thread_id++)
+  {
+    //for (int ijk=0;ijk<m;ijk++) printf("aaaaaaaaaaaaaaaaaaaaa> id:%d jb[%d]=%d\n",thread_id,ijk,jb[ijk]);
 
-          // accumulate step*torques
-          tmp3[j] = stepsize*(b->tacc[j] + f_damp_ptr[j+3]);
-        }
-        // v_damp = invI * f_damp
-        dMultiplyAdd0_331 (v_damp_ptr+3, invIrow, tmp3);
+    int nStart = i - num_overlap < 0 ? 0 : i - num_overlap;
+    int nEnd   = i + chunk + num_overlap;
+    if (nEnd > m) nEnd = m;
+    // if every one reorders constraints, this might just work
+    // comment out below if using defaults (0 and m) so every thread runs through all joints
+    tmpInt[0+thread_id*tmpInt_size] = nStart;   // 0
+    tmpInt[1+thread_id*tmpInt_size] = nEnd - nStart; // m
+    tmpInt[2+thread_id*tmpInt_size] = m; // m
+    tmpInt[3+thread_id*tmpInt_size] = nb;
+    tmpInt[4+thread_id*tmpInt_size] = m_damp;
+    tmpInt[5+thread_id*tmpInt_size] = num_iterations;
+    tmpReal[0+thread_id*tmpReal_size] = stepsize;
+    tmpReal[1+thread_id*tmpReal_size] = qs->sor_lcp_tolerance;
+    tmpIntPtr[0+thread_id*tmpIntPtr_size] = jb;
+    tmpIntPtr[1+thread_id*tmpIntPtr_size] = findex;
+    tmpIntPtr[2+thread_id*tmpIntPtr_size] = jb_damp;
+    tmpRealPtr[0+thread_id*tmpRealPtr_size] = Ad;
+    tmpRealPtr[1+thread_id*tmpRealPtr_size] = hi;
+    tmpRealPtr[2+thread_id*tmpRealPtr_size] = lo;
+    tmpRealPtr[3+thread_id*tmpRealPtr_size] = Adcfm;
+    tmpRealPtr[4+thread_id*tmpRealPtr_size] = JiM;
+    tmpRealPtr[5+thread_id*tmpRealPtr_size] = invI;
+    tmpRealPtr[6+thread_id*tmpRealPtr_size] = coeff_damp ;
+    tmpMutablePtr[0+thread_id*tmpMutablePtr_size] = b;
+    tmpMutablePtr[1+thread_id*tmpMutablePtr_size] = J;
+    tmpMutablePtr[2+thread_id*tmpMutablePtr_size] = fc;
+    tmpMutablePtr[3+thread_id*tmpMutablePtr_size] = lambda;
+    tmpMutablePtr[4+thread_id*tmpMutablePtr_size] = iMJ;
+    #ifdef USE_JOINT_DAMPING
+      tmpMutablePtr[5+thread_id*tmpMutablePtr_size] = b_damp;
+      tmpMutablePtr[6+thread_id*tmpMutablePtr_size] = f_damp;
+      tmpMutablePtr[7+thread_id*tmpMutablePtr_size] = v_damp;
+      tmpMutablePtr[8+thread_id*tmpMutablePtr_size] = J_damp;
+      tmpMutablePtr[9+thread_id*tmpMutablePtr_size] = v_joint_damp;
+      #ifdef REORDER_CONSTRAINTS
+        tmpMutablePtr[10+thread_id*tmpMutablePtr_size] = last_lambda;
+      #endif
+    #endif
+    tmpMutablePtr[11+thread_id*tmpMutablePtr_size] = delta_error ;
+    tmpMutablePtr[12+thread_id*tmpMutablePtr_size] = lambda_qr ;
 
-      }
-    }
+    #ifdef REPORT_MONITOR
+      printf("thread summary: id %d i %d m %d chunk %d start %d end %d \n",thread_id,i,m,chunk,nStart,nEnd);
+    #endif
+#ifdef USE_TPROW
+    if (row_threadpool->size() > 1)
+      row_threadpool->schedule(boost::bind(ComputeRows,thread_id,order, body, tmpInt+thread_id*tmpInt_size,
+                           tmpReal+thread_id*tmpReal_size, tmpIntPtr+thread_id*tmpIntPtr_size,
+                           tmpRealPtr+thread_id*tmpRealPtr_size, tmpMutablePtr+thread_id*tmpMutablePtr_size, mutex));
+    else //automatically skip threadpool if only 1 thread allocated
+      ComputeRows(thread_id,order, body, tmpInt+thread_id*tmpInt_size,
+                           tmpReal+thread_id*tmpReal_size, tmpIntPtr+thread_id*tmpIntPtr_size,
+                           tmpRealPtr+thread_id*tmpRealPtr_size, tmpMutablePtr+thread_id*tmpMutablePtr_size, mutex);
+#else
+    ComputeRows(thread_id,order, body, tmpInt+thread_id*tmpInt_size,
+                           tmpReal+thread_id*tmpReal_size, tmpIntPtr+thread_id*tmpIntPtr_size,
+                           tmpRealPtr+thread_id*tmpRealPtr_size, tmpMutablePtr+thread_id*tmpMutablePtr_size, mutex);
+#endif
 
     /****************************************************************/
     /* compute f_damp per v_damp update                             */
@@ -723,6 +1077,31 @@
 
 
   } // end of for loop on iterations
+
+
+  // check time for scheduling, this is usually very quick
+  //gettimeofday(&tv,NULL);
+  //double wait_time = (double)tv.tv_sec + (double)tv.tv_usec / 1.e6;
+  //printf("      quickstep done scheduling start time %f stopped time %f duration %f\n",cur_time,wait_time,wait_time - cur_time);
+
+#ifdef USE_TPROW
+  IFTIMING (dTimerNow ("wait for threads"));
+  if (row_threadpool->size() > 1)
+    row_threadpool->wait();
+  IFTIMING (dTimerNow ("threads done"));
+#endif
+
+
+
+  gettimeofday(&tv,NULL);
+  double end_time = (double)tv.tv_sec + (double)tv.tv_usec / 1.e6;
+  #ifdef REPORT_THREAD_TIMING
+  printf("    quickstep threads start time %f stopped time %f duration %f\n",cur_time,end_time,end_time - cur_time);
+  #endif
+
+
+
+  delete mutex;
 }
 
 struct dJointWithInfo1
@@ -735,6 +1114,11 @@
   dxWorld *world, dxBody * const *body, int nb,
   dxJoint * const *_joint, int _nj, dReal stepsize)
 {
+
+  //int mpi_rank = MPI::COMM_WORLD.Get_rank();
+  //int mpi_nprocs = MPI::COMM_WORLD.Get_size();
+  //printf("-------------\ndebug opende %d %d\n-------------\n",mpi_rank,mpi_nprocs);
+
   IFTIMING(dTimerStart("preprocessing"));
 
   const dReal stepsize1 = dRecip(stepsize);
@@ -1083,6 +1467,7 @@
           }
         }
         dIASSERT (jb_ptr == jb+2*m);
+        //printf("jjjjjjjjj %d %d\n",jb[0],jb[1]);
       }
 
 #ifdef USE_JOINT_DAMPING
@@ -1202,6 +1587,7 @@
 
     // load lambda from the value saved on the previous iteration
     dReal *lambda = context->AllocateArray<dReal> (m);
+    dReal *lambda_qr = context->AllocateArray<dReal> (m);
 
 #ifdef WARM_STARTING
     {
@@ -1224,10 +1610,13 @@
     BEGIN_STATE_SAVE(context, lcpstate) {
       IFTIMING (dTimerNow ("solving LCP problem"));
       // solve the LCP problem and get lambda and invM*constraint_force
-      SOR_LCP (context,m,nb,J,jb,body,invI,lambda,cforce,rhs,lo,hi,cfm,findex,&world->qs,
+      SOR_LCP (context,m,nb,J,jb,body,invI,lambda,lambda_qr,cforce,rhs,lo,hi,cfm,findex,&world->qs,
 #ifdef USE_JOINT_DAMPING
                m_damp,J_damp,coeff_damp,jb_damp,v_damp,f_damp,v_joint_damp,JiM,
 #endif
+#ifdef USE_TPROW
+               world->row_threadpool,
+#endif
                stepsize);
 
     } END_STATE_SAVE(context, lcpstate);
@@ -1255,7 +1644,6 @@
     /****************************************************************/
     {
       const dReal *invIrow = invI;
-      IFTIMING (dTimerNow ("velocity update due to f_damp"));
 
       dRealMutablePtr f_damp_ptr = f_damp;
       dxBody *const *const bodyend = body + nb;
@@ -1403,6 +1791,7 @@
 
   IFTIMING (dTimerEnd());
   IFTIMING (if (m > 0) dTimerReport (stdout,1));
+
 }
 
 #ifdef USE_CG_LCP
@@ -1423,6 +1812,7 @@
   size_t res = dEFFICIENT_SIZE(sizeof(dReal) * 12 * m); // for iMJ
   res += dEFFICIENT_SIZE(sizeof(dReal) * m); // for Ad
   res += dEFFICIENT_SIZE(sizeof(dReal) * m); // for Adcfm
+  res += dEFFICIENT_SIZE(sizeof(dReal) * m); // for delta_error
   res += dEFFICIENT_SIZE(sizeof(IndexError) * m); // for order
 #ifdef REORDER_CONSTRAINTS
   res += dEFFICIENT_SIZE(sizeof(dReal) * m); // for last_lambda
@@ -1488,14 +1878,14 @@
     if (m > 0) {
       sub1_res2 += dEFFICIENT_SIZE(sizeof(dReal) * 12 * m); // for J
       sub1_res2 += 4 * dEFFICIENT_SIZE(sizeof(dReal) * m); // for cfm, lo, hi, rhs
-      sub1_res2 += dEFFICIENT_SIZE(sizeof(int) * 12 * m); // for jb            FIXME: shoulbe be 2 not 12?
+      sub1_res2 += dEFFICIENT_SIZE(sizeof(int) * 2 * m); // for jb            FIXME: shoulbe be 2 not 12?
       sub1_res2 += dEFFICIENT_SIZE(sizeof(int) * m); // for findex
       sub1_res2 += dEFFICIENT_SIZE(sizeof(dReal) * 12 * mfb); // for Jcopy
 
 #ifdef USE_JOINT_DAMPING
       sub1_res2 += dEFFICIENT_SIZE(sizeof(dReal) * 12 * m_damp); // for J_damp
       sub1_res2 += dEFFICIENT_SIZE(sizeof(dReal) * m_damp ); // for v_joint_damp
-      sub1_res2 += dEFFICIENT_SIZE(sizeof(int) * 12 * m_damp); // for jb_damp            FIXME: shoulbe be 2 not 12?
+      sub1_res2 += dEFFICIENT_SIZE(sizeof(int) * 2 * m_damp); // for jb_damp            FIXME: shoulbe be 2 not 12?
       sub1_res2 += dEFFICIENT_SIZE(sizeof(dReal) * 6 * nb); // for f_damp
       sub1_res2 += dEFFICIENT_SIZE(sizeof(dReal) * 12*m); // for JiM
       sub1_res2 += dEFFICIENT_SIZE(sizeof(dReal) * 6 * nb); // for v_damp
@@ -1512,6 +1902,7 @@
         }
 
         size_t sub2_res2 = dEFFICIENT_SIZE(sizeof(dReal) * m); // for lambda
+        sub2_res2 += dEFFICIENT_SIZE(sizeof(dReal) * m); // for lambda_qr
         sub2_res2 += dEFFICIENT_SIZE(sizeof(dReal) * 6 * nb); // for cforce
         {
           size_t sub3_res1 = EstimateSOR_LCPMemoryRequirements(m
